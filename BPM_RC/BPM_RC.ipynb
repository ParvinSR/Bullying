{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.11"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lAumGnrPTI-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mmqSh3szedt"
      },
      "source": [
        "! pip3 install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0Yf9E5vzfsU"
      },
      "source": [
        "%cd /content/drive/MyDrive/BPM_RC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class DataPrecessForSentence(Dataset):\n",
        "    \"\"\"\n",
        "    Encoding sentences\n",
        "    \"\"\"\n",
        "    def __init__(self, bert_tokenizer, df, max_seq_len = 50):\n",
        "        super(DataPrecessForSentence, self).__init__()\n",
        "        self.bert_tokenizer = bert_tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.input_ids, self.attention_mask, self.token_type_ids, self.labels = self.get_input(df)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attention_mask[idx], self.token_type_ids[idx], self.labels[idx]\n",
        "        \n",
        "    # Convert dataframe to tensor\n",
        "    def get_input(self, df):\n",
        "        sentences = df['p1'].values + str(df['p2'])\n",
        "        labels = df['similarity'].values\n",
        "        \n",
        "\n",
        "\n",
        "    # tokenizer\n",
        "        tokens_seq = list(map(self.bert_tokenizer.tokenize, sentences)) # list of shape [sentence_len, token_len]\n",
        "        \n",
        "        # Get fixed-length sequence and its mask\n",
        "        result = list(map(self.trunate_and_pad, tokens_seq))\n",
        "        \n",
        "        input_ids = [i[0] for i in result]\n",
        "        attention_mask = [i[1] for i in result]\n",
        "        token_type_ids = [i[2] for i in result]\n",
        "        \n",
        "        return (\n",
        "               torch.Tensor(input_ids).type(torch.long), \n",
        "               torch.Tensor(attention_mask).type(torch.long),\n",
        "               torch.Tensor(token_type_ids).type(torch.long), \n",
        "               torch.Tensor(labels).type(torch.long)\n",
        "               )\n",
        "    \n",
        "    \n",
        "    def trunate_and_pad(self, tokens_seq):\n",
        "        \n",
        "        # Concat '[CLS]' at the beginning\n",
        "        tokens_seq = ['[CLS]'] + tokens_seq     \n",
        "        # Truncate sequences of which the lengths exceed the max_seq_len\n",
        "        if len(tokens_seq) > self.max_seq_len:\n",
        "            tokens_seq = tokens_seq[0 : self.max_seq_len]           \n",
        "        # Generate padding\n",
        "        padding = [0] * (self.max_seq_len - len(tokens_seq))       \n",
        "        # Convert tokens_seq to token_ids\n",
        "        input_ids = self.bert_tokenizer.convert_tokens_to_ids(tokens_seq)\n",
        "        input_ids += padding   \n",
        "        # Create attention_mask\n",
        "        attention_mask = [1] * len(tokens_seq) + padding     \n",
        "        # Create token_type_ids\n",
        "        token_type_ids = [0] * (self.max_seq_len)\n",
        "        \n",
        "        assert len(input_ids) == self.max_seq_len\n",
        "        assert len(attention_mask) == self.max_seq_len\n",
        "        assert len(token_type_ids) == self.max_seq_len\n",
        "        \n",
        "        return input_ids, attention_mask, token_type_ids"
      ],
      "metadata": {
        "id": "sAzYboa4XYe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type('p1'))\n",
        "print(type('p2'))\n",
        "print(type('p3'))\n",
        "print(type('p4'))"
      ],
      "metadata": {
        "id": "krMfAsv2Ewwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "110a798a-e302-47e8-df52-93def6c8d9cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, \n",
        "    accuracy_score, \n",
        "    precision_score, \n",
        "    recall_score, \n",
        "    f1_score, \n",
        "    classification_report\n",
        ")   \n",
        "\n",
        "    \n",
        "def Metric(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    compute and show the classification result\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    macro_precision = precision_score(y_true, y_pred, average='macro')\n",
        "    macro_recall = recall_score(y_true, y_pred, average='macro')\n",
        "    weighted_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    target_names = ['class_0', 'class_1']\n",
        "    report = classification_report(y_true, y_pred, target_names=target_names, digits=3)\n",
        "\n",
        "    print('Accuracy: {:.1%}\\nPrecision: {:.1%}\\nRecall: {:.1%}\\nF1: {:.1%}'.format(accuracy, macro_precision,\n",
        "                                           macro_recall, weighted_f1))\n",
        "    print(\"classification_report:\\n\")\n",
        "    print(report)\n",
        "  \n",
        "  \n",
        "def correct_predictions(output_probabilities, targets):\n",
        "    \"\"\"\n",
        "    Compute the number of predictions that match some target classes in the\n",
        "    output of a model.\n",
        "    Args:\n",
        "        output_probabilities: A tensor of probabilities for different output\n",
        "            classes.\n",
        "        targets: The indices of the actual target classes.\n",
        "    Returns:\n",
        "        The number of correct predictions in 'output_probabilities'.\n",
        "    \"\"\"\n",
        "    _, out_classes = output_probabilities.max(dim=1)\n",
        "    correct = (out_classes == targets).sum()\n",
        "    return correct.item()\n",
        "\n",
        "\n",
        "def train(model, dataloader, optimizer, epoch_number, max_gradient_norm):\n",
        "    \"\"\"\n",
        "    Train a model for one epoch on some input data with a given optimizer and\n",
        "    criterion.\n",
        "    Args:\n",
        "        model: A torch module that must be trained on some input data.\n",
        "        dataloader: A DataLoader object to iterate over the training data.\n",
        "        optimizer: A torch optimizer to use for training on the input model.\n",
        "        epoch_number: The number of the epoch for which training is performed.\n",
        "        max_gradient_norm: Max. norm for gradient norm clipping.\n",
        "    Returns:\n",
        "        epoch_time: The total time necessary to train the epoch.\n",
        "        epoch_loss: The training loss computed for the epoch.\n",
        "        epoch_accuracy: The accuracy computed for the epoch.\n",
        "    \"\"\"\n",
        "    # Switch the model to train mode.\n",
        "    model.train()\n",
        "    device = model.device\n",
        "    epoch_start = time.time()\n",
        "    batch_time_avg = 0.0\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    tqdm_batch_iterator = tqdm(dataloader)\n",
        "    for batch_index, (batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels) in enumerate(tqdm_batch_iterator):\n",
        "        batch_start = time.time()\n",
        "        # Move input and output data to the GPU if it is used.\n",
        "        seqs, masks, segments, labels = batch_seqs.to(device), batch_seq_masks.to(device), batch_seq_segments.to(device), batch_labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss, logits, probabilities = model(seqs, masks, segments, labels)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_gradient_norm)\n",
        "        optimizer.step()\n",
        "        batch_time_avg += time.time() - batch_start\n",
        "        running_loss += loss.item()\n",
        "        correct_preds += correct_predictions(probabilities, labels)\n",
        "        description = \"Avg. batch proc. time: {:.4f}s, loss: {:.4f}\"\\\n",
        "                      .format(batch_time_avg/(batch_index+1), running_loss/(batch_index+1))\n",
        "        tqdm_batch_iterator.set_description(description)\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_accuracy = correct_preds / len(dataloader.dataset)\n",
        "    return epoch_time, epoch_loss, epoch_accuracy\n",
        "\n",
        "\n",
        "def validate(model, dataloader):\n",
        "    \"\"\"\n",
        "    Compute the loss and accuracy of a model on some validation dataset.\n",
        "    Args:\n",
        "        model: A torch module for which the loss and accuracy must be\n",
        "            computed.\n",
        "        dataloader: A DataLoader object to iterate over the validation data.\n",
        "    Returns:\n",
        "        epoch_time: The total time to compute the loss and accuracy on the\n",
        "            entire validation set.\n",
        "        epoch_loss: The loss computed on the entire validation set.\n",
        "        epoch_accuracy: The accuracy computed on the entire validation set.\n",
        "        roc_auc_score(all_labels, all_prob): The auc computed on the entire validation set.\n",
        "        all_prob: The probability of classification as label 1 on the entire validation set.\n",
        "    \"\"\"\n",
        "    # Switch to evaluate mode.\n",
        "    model.eval()\n",
        "    device = model.device\n",
        "    epoch_start = time.time()\n",
        "    running_loss = 0.0\n",
        "    running_accuracy = 0.0\n",
        "    all_prob = []\n",
        "    all_labels = []\n",
        "    # Deactivate autograd for evaluation.\n",
        "    with torch.no_grad():\n",
        "        for (batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels) in dataloader:\n",
        "            # Move input and output data to the GPU if one is used.\n",
        "            seqs = batch_seqs.to(device)\n",
        "            masks = batch_seq_masks.to(device)\n",
        "            segments = batch_seq_segments.to(device)\n",
        "            labels = batch_labels.to(device)\n",
        "            loss, logits, probabilities = model(seqs, masks, segments, labels)\n",
        "            running_loss += loss.item()\n",
        "            running_accuracy += correct_predictions(probabilities, labels)\n",
        "            all_prob.extend(probabilities[:,1].cpu().numpy())\n",
        "            all_labels.extend(batch_labels)\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_accuracy = running_accuracy / (len(dataloader.dataset))\n",
        "    return epoch_time, epoch_loss, epoch_accuracy, roc_auc_score(all_labels, all_prob), all_prob\n",
        "\n",
        "\n",
        "def test(model, dataloader):\n",
        "    \"\"\"\n",
        "    Test the accuracy of a model on some labelled test dataset.\n",
        "    Args:\n",
        "        model: The torch module on which testing must be performed.\n",
        "        dataloader: A DataLoader object to iterate over some dataset.\n",
        "    Returns:\n",
        "        batch_time: The average time to predict the classes of a batch.\n",
        "        total_time: The total time to process the whole dataset.\n",
        "        accuracy: The accuracy of the model on the input data.\n",
        "        all_prob: The probability of classification as label 1 on the entire validation set.\n",
        "    \"\"\"\n",
        "    # Switch the model to eval mode.\n",
        "    model.eval()\n",
        "    device = model.device\n",
        "    time_start = time.time()\n",
        "    batch_time = 0.0\n",
        "    accuracy = 0.0\n",
        "    all_prob = []\n",
        "    all_labels = []\n",
        "    # Deactivate autograd for evaluation.\n",
        "    with torch.no_grad():\n",
        "        for (batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels) in dataloader:\n",
        "            batch_start = time.time()\n",
        "            # Move input and output data to the GPU if one is used.\n",
        "            seqs, masks, segments, labels = batch_seqs.to(device), batch_seq_masks.to(device), batch_seq_segments.to(device), batch_labels.to(device)\n",
        "            _, _, probabilities = model(seqs, masks, segments, labels)\n",
        "            accuracy += correct_predictions(probabilities, labels)\n",
        "            batch_time += time.time() - batch_start\n",
        "            all_prob.extend(probabilities[:,1].cpu().numpy())\n",
        "            all_labels.extend(batch_labels)\n",
        "    batch_time /= len(dataloader)\n",
        "    total_time = time.time() - time_start\n",
        "    accuracy /= (len(dataloader.dataset))\n",
        "\n",
        "    return batch_time, total_time, accuracy, all_prob\n",
        "\n"
      ],
      "metadata": {
        "id": "sBzdYIx4Xnuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import (\n",
        "    BertForSequenceClassification,\n",
        "    AlbertForSequenceClassification,  \n",
        "    AutoTokenizer\n",
        ")\n",
        "\n",
        "\n",
        "class AlbertModel(nn.Module):\n",
        "    def __init__(self, requires_grad = True):\n",
        "        super(AlbertModel, self).__init__()\n",
        "        self.albert = AlbertForSequenceClassification.from_pretrained('albert-xxlarge-v2', num_labels = 2)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('albert-xxlarge-v2', do_lower_case=True)\n",
        "        self.requires_grad = requires_grad\n",
        "        self.device = torch.device(\"cuda\")\n",
        "        for param in self.albert.parameters():\n",
        "            param.requires_grad = True  # Each parameter requires gradient\n",
        "\n",
        "    def forward(self, batch_seqs, batch_seq_masks, batch_seq_segments, labels):\n",
        "        loss, logits = self.albert(input_ids = batch_seqs, attention_mask = batch_seq_masks, \n",
        "                              token_type_ids=batch_seq_segments, labels = labels)[:2]\n",
        "        probabilities = nn.functional.softmax(logits, dim=-1)\n",
        "        return loss, logits, probabilities\n",
        "        \n",
        "     \n",
        "        \n",
        "class BertModel(nn.Module):\n",
        "    def __init__(self, requires_grad = True):\n",
        "        super(BertModel, self).__init__()\n",
        "        self.bert = BertForSequenceClassification.from_pretrained('textattack/bert-base-uncased-SST-2',num_labels = 2)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('textattack/bert-base-uncased-SST-2', do_lower_case=True)\n",
        "        self.requires_grad = requires_grad\n",
        "        self.device = torch.device(\"cuda\")\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = requires_grad  # Each parameter requires gradient\n",
        "\n",
        "    def forward(self, batch_seqs, batch_seq_masks, batch_seq_segments, labels):\n",
        "        loss, logits = self.bert(input_ids = batch_seqs, attention_mask = batch_seq_masks, \n",
        "                              token_type_ids=batch_seq_segments, labels = labels)[:2]\n",
        "        probabilities = nn.functional.softmax(logits, dim=-1)\n",
        "        return loss, logits, probabilities"
      ],
      "metadata": {
        "id": "o6UyV5dBYJ1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "metadata": {
        "id": "ZzArt8ghZ729"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    import torch\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "0eaWqQOTbpxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers.optimization import AdamW\n",
        "from sys import platform\n",
        "\n",
        "def model_train_validate_test(train_df, dev_df, test_df, target_dir, \n",
        "         max_seq_len=50,\n",
        "         epochs=3,\n",
        "         batch_size=32,\n",
        "         lr=2e-05,\n",
        "         patience=1,\n",
        "         max_grad_norm=10.0,\n",
        "         if_save_model=True,\n",
        "         checkpoint=None):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_df : pandas dataframe of train set.\n",
        "    dev_df : pandas dataframe of dev set.\n",
        "    test_df : pandas dataframe of test set.\n",
        "    target_dir : the path where you want to save model.\n",
        "    max_seq_len: the max truncated length.\n",
        "    epochs : the default is 3.\n",
        "    batch_size : the default is 32.\n",
        "    lr : learning rate, the default is 2e-05.\n",
        "    patience : the default is 1.\n",
        "    max_grad_norm : the default is 10.0.\n",
        "    if_save_model: if save the trained model to the target dir.\n",
        "    checkpoint : the default is None.\n",
        "\n",
        "    \"\"\"\n",
        "    bertmodel = AlbertModel(requires_grad = True)\n",
        "    tokenizer = bertmodel.tokenizer\n",
        "    \n",
        "    print(20 * \"=\", \" Preparing for training \", 20 * \"=\")\n",
        "    # Path to save the model, create a folder if not exist.\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.makedirs(target_dir)\n",
        "        \n",
        "    # -------------------- Data loading --------------------------------------#\n",
        "    \n",
        "    print(\"\\t* Loading training data...\")\n",
        "    train_data = DataPrecessForSentence(tokenizer, train_df, max_seq_len = max_seq_len)\n",
        "    train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "    print(\"\\t* Loading validation data...\")\n",
        "    dev_data = DataPrecessForSentence(tokenizer,dev_df, max_seq_len = max_seq_len)\n",
        "    dev_loader = DataLoader(dev_data, shuffle=True, batch_size=batch_size)\n",
        "    \n",
        "    print(\"\\t* Loading test data...\")\n",
        "    test_data = DataPrecessForSentence(tokenizer,test_df, max_seq_len = max_seq_len) \n",
        "    test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
        "    \n",
        "    # -------------------- Model definition ------------------- --------------#\n",
        "    \n",
        "    print(\"\\t* Building model...\")\n",
        "    device = torch.device(\"cuda\")\n",
        "    model = bertmodel.to(device)\n",
        "    \n",
        "    # -------------------- Preparation for training  -------------------------#\n",
        "    \n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "            {\n",
        "                    'params':[p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "                    'weight_decay':0.01\n",
        "            },\n",
        "            {\n",
        "                    'params':[p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "                    'weight_decay':0.0\n",
        "            }\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
        "\n",
        "    ## Implement of warm up\n",
        "    ## total_steps = len(train_loader) * epochs\n",
        "    ## scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=60, num_training_steps=total_steps)\n",
        "    \n",
        "    # When the monitored value is not improving, the network performance could be improved by reducing the learning rate.\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.85, patience=0)\n",
        "\n",
        "    best_score = 0.0\n",
        "    start_epoch = 1\n",
        "    # Data for loss curves plot\n",
        "    epochs_count = []\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    valid_losses = []\n",
        "    valid_accuracies = []\n",
        "    valid_aucs = []\n",
        "    \n",
        "    # Continuing training from a checkpoint if one was given as argument\n",
        "    if checkpoint:\n",
        "        checkpoint = torch.load(checkpoint)\n",
        "        start_epoch = checkpoint[\"epoch\"] + 1\n",
        "        best_score = checkpoint[\"best_score\"]\n",
        "        print(\"\\t* Training will continue on existing model from epoch {}...\".format(start_epoch))\n",
        "        model.load_state_dict(checkpoint[\"model\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "        epochs_count = checkpoint[\"epochs_count\"]\n",
        "        train_losses = checkpoint[\"train_losses\"]\n",
        "        train_accuracy = checkpoint[\"train_accuracy\"]\n",
        "        valid_losses = checkpoint[\"valid_losses\"]\n",
        "        valid_accuracy = checkpoint[\"valid_accuracy\"]\n",
        "        valid_auc = checkpoint[\"valid_auc\"]\n",
        "        \n",
        "     # Compute loss and accuracy before starting (or resuming) training.\n",
        "    _, valid_loss, valid_accuracy, auc, _, = validate(model, dev_loader)\n",
        "    print(\"\\n* Validation loss before training: {:.4f}, accuracy: {:.4f}%, auc: {:.4f}\".format(valid_loss, (valid_accuracy*100), auc))\n",
        "    \n",
        "    # -------------------- Training epochs -----------------------------------#\n",
        "    \n",
        "    print(\"\\n\", 20 * \"=\", \"Training bert model on device: {}\".format(device), 20 * \"=\")\n",
        "    patience_counter = 0\n",
        "    for epoch in range(start_epoch, epochs + 1):\n",
        "        epochs_count.append(epoch)\n",
        "\n",
        "        print(\"* Training epoch {}:\".format(epoch))\n",
        "        epoch_time, epoch_loss, epoch_accuracy = train(model, train_loader, optimizer, epoch, max_grad_norm)\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accuracies.append(epoch_accuracy)  \n",
        "        print(\"-> Training time: {:.4f}s, loss = {:.4f}, accuracy: {:.4f}%\".format(epoch_time, epoch_loss, (epoch_accuracy*100)))\n",
        "        \n",
        "        print(\"* Validation for epoch {}:\".format(epoch))\n",
        "        epoch_time, epoch_loss, epoch_accuracy , epoch_auc, _, = validate(model, dev_loader)\n",
        "        valid_losses.append(epoch_loss)\n",
        "        valid_accuracies.append(epoch_accuracy)\n",
        "        valid_aucs.append(epoch_auc)\n",
        "        print(\"-> Valid. time: {:.4f}s, loss: {:.4f}, accuracy: {:.4f}%, auc: {:.4f}\\n\"\n",
        "              .format(epoch_time, epoch_loss, (epoch_accuracy*100), epoch_auc))\n",
        "        \n",
        "        # Update the optimizer's learning rate with the scheduler.\n",
        "        scheduler.step(epoch_accuracy)\n",
        "        ## scheduler.step()\n",
        "        \n",
        "        # Early stopping on validation accuracy.\n",
        "        if epoch_accuracy < best_score:\n",
        "            patience_counter += 1\n",
        "        else:\n",
        "            best_score = epoch_accuracy\n",
        "            patience_counter = 0\n",
        "            if (if_save_model):\n",
        "                  torch.save({\"epoch\": epoch, \n",
        "                           \"model\": model.state_dict(),\n",
        "                           \"optimizer\": optimizer.state_dict(),\n",
        "                           \"best_score\": best_score,\n",
        "                           \"epochs_count\": epochs_count,\n",
        "                           \"train_losses\": train_losses,\n",
        "                           \"train_accuracy\": train_accuracies,\n",
        "                           \"valid_losses\": valid_losses,\n",
        "                           \"valid_accuracy\": valid_accuracies,\n",
        "                           \"valid_auc\": valid_aucs\n",
        "                           },\n",
        "                           os.path.join(target_dir, \"best.pth.tar\"))\n",
        "                  print(\"save model succesfully!\\n\")\n",
        "            \n",
        "            # run model on test set and save the prediction result to csv\n",
        "            print(\"* Test for epoch {}:\".format(epoch))\n",
        "            _, _, test_accuracy, _, all_prob = validate(model, test_loader)\n",
        "            print(\"Test accuracy: {:.4f}%\\n\".format(test_accuracy))\n",
        "            test_prediction = pd.DataFrame({'prob_1':all_prob})\n",
        "            test_prediction['prob_0'] = 1-test_prediction['prob_1']\n",
        "            test_prediction['prediction'] = test_prediction.apply(lambda x: 0 if (x['prob_0'] > x['prob_1']) else 1, axis=1)\n",
        "            test_prediction = test_prediction[['prob_0', 'prob_1', 'prediction']]\n",
        "            test_prediction.to_csv(os.path.join(target_dir,\"test_prediction.csv\"), index=False)\n",
        "             \n",
        "        if patience_counter >= patience:\n",
        "            print(\"-> Early stopping: patience limit reached, stopping...\")\n",
        "            break\n",
        "\n",
        "\n",
        "def model_load_test(test_df, target_dir, test_prediction_dir, test_prediction_name, max_seq_len=50, batch_size=32):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    test_df : pandas dataframe of test set.\n",
        "    target_dir : the path of pretrained model.\n",
        "    test_prediction_dir : the path that you want to save the prediction result to.\n",
        "    test_prediction_name : the file name of the prediction result.\n",
        "    max_seq_len: the max truncated length.\n",
        "    batch_size : the default is 32.\n",
        "    \n",
        "    \"\"\"\n",
        "    bertmodel = AlbertModel(requires_grad = False)\n",
        "    tokenizer = bertmodel.tokenizer\n",
        "    device = torch.device(\"cuda\")\n",
        "    \n",
        "    print(20 * \"=\", \" Preparing for testing \", 20 * \"=\")\n",
        "    if platform == \"linux\" or platform == \"linux2\":\n",
        "        checkpoint = torch.load(os.path.join(target_dir, \"best.pth.tar\"))\n",
        "    else:\n",
        "        checkpoint = torch.load(os.path.join(target_dir, \"best.pth.tar\"), map_location=device)\n",
        "        \n",
        "    print(\"\\t* Loading test data...\")    \n",
        "    test_data = DataPrecessForSentence(tokenizer,test_df, max_seq_len = max_seq_len) \n",
        "    test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "    # Retrieving model parameters from checkpoint.\n",
        "    print(\"\\t* Building model...\")\n",
        "    model = bertmodel.to(device)\n",
        "    model.load_state_dict(checkpoint[\"model\"])\n",
        "    print(20 * \"=\", \" Testing BERT model on device: {} \".format(device), 20 * \"=\")\n",
        "    \n",
        "    batch_time, total_time, accuracy, all_prob = test(model, test_loader)\n",
        "    print(\"\\n-> Average batch processing time: {:.4f}s, total test time: {:.4f}s, accuracy: {:.4f}%\\n\".format(batch_time, total_time, (accuracy*100)))\n",
        "    \n",
        "    test_prediction = pd.DataFrame({'prob_1':all_prob})\n",
        "    test_prediction['prob_0'] = 1-test_prediction['prob_1']\n",
        "    test_prediction['prediction'] = test_prediction.apply(lambda x: 0 if (x['prob_0'] > x['prob_1']) else 1, axis=1)\n",
        "    test_prediction = test_prediction[['prob_0', 'prob_1', 'prediction']]\n",
        "    if not os.path.exists(test_prediction_dir):\n",
        "        os.makedirs(test_prediction_dir)\n",
        "    test_prediction.to_csv(os.path.join(test_prediction_dir, test_prediction_name), index=False)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data_path = \"/content/drive/MyDrive/BPM_RC\"\n",
        "    train_df = pd.read_csv(os.path.join(data_path,\"train.txt\"),sep='\\t',header=None, names=['similarity','p1', str('p2')])\n",
        "    dev_df = pd.read_csv(os.path.join(data_path,\"dev.txt\"),sep='\\t',header=None, names=['similarity','p1', str('p2')])\n",
        "    test_df = pd.read_csv(os.path.join(data_path,\"test.txt\"),sep='\\t',header=None, names=['similarity','p1', str('p2')])\n",
        "    target_dir = \"/content/drive/MyDrive/BPM_RC\"\n",
        "    model_train_validate_test(train_df, dev_df, test_df, target_dir)"
      ],
      "metadata": {
        "id": "89GT22dEaaJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNDyLJErqdij"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/BPM_RC\"\n",
        "train_df = pd.read_csv(os.path.join(data_path,\"train.txt\"),sep='\\t',header=None, names=['similarity','p1', str('p2')])\n",
        "dev_df = pd.read_csv(os.path.join(data_path,\"dev.txt\"),sep='\\t',header=None, names=['similarity','p1', str('p2')])\n",
        "test_df = pd.read_csv(os.path.join(data_path,\"test.txt\"),sep='\\t',header=None, names=['similarity','p1', str('p2')])\n",
        "target_dir = \"/content/drive/MyDrive/BPM_RC\"\n",
        "\n",
        "model_train_validate_test(train_df, dev_df, test_df, target_dir, \n",
        "         max_seq_len=50,\n",
        "         epochs=3,\n",
        "         batch_size=32,\n",
        "         lr=2e-05,\n",
        "         patience=1,\n",
        "         max_grad_norm=10.0,\n",
        "         if_save_model=True,\n",
        "         checkpoint=None)\n",
        "\n",
        "test_result = pd.read_csv(os.path.join(target_dir, 'test_prediction.csv'))\n",
        "Metric(test_df.similarity, test_result.prediction) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}